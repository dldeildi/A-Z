{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvowx9J7D7kC",
        "outputId": "5b07489d-66be-4f97-a405-23fe1b3e6821"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sv738JrND987"
      },
      "outputs": [],
      "source": [
        "# !unzip -qq /content/drive/MyDrive/alphabet.zip -d /content/drive/MyDrive/datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GE2LtDexEES0"
      },
      "outputs": [],
      "source": [
        "# !pip install -q tensorflow-gpu==2.0.0-rc1\n",
        "# !pip install -q tensorflow-gpu==2.8.0-rc1\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "t1DtaKx5SD_g"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import os\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/datasets/\"\n",
        "# data_dir = pathlib.Path(data_dir)\n",
        "\n",
        "# train_dir = os.path.join(data_dir, 'train')\n",
        "# test_dir = os.path.join(data_dir, 'test')\n",
        "\n",
        "train_dir = \"/content/drive/MyDrive/datasets/train/\"\n",
        "test_dir = \"/content/drive/MyDrive/datasets/test/\"\n",
        "val_dir = \"/content/drive/MyDrive/datasets/validation\"\n",
        "\n",
        "# image_count = len(list(data_dir.glob('A/*.png')))\n",
        "# print(image_count)\n",
        "# image_count = len(list(data_dir.glob('lower_a/*.png')))\n",
        "# print(image_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Nr8N0JCILvtg"
      },
      "outputs": [],
      "source": [
        "# 이미지 데이터 전처리\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Image augmentation\n",
        "# train셋에만 적용\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255, # 모든 이미지 원소값들을 255로 나누기\n",
        "                                   rotation_range=25, # 0~25도 사이에서 임의의 각도로 원본이미지를 회전\n",
        "                                   width_shift_range=0.1, # 0.05범위 내에서 임의의 값만큼 임의의 방향으로 좌우 이동\n",
        "                                   height_shift_range=0.1, # 0.05범위 내에서 임의의 값만큼 임의의 방향으로 상하 이동\n",
        "                                   zoom_range=0.2, # (1-0.2)~(1+0.2) => 0.8~1.2 사이에서 임의의 수치만큼 확대/축소\n",
        "                                   horizontal_flip=True, # 좌우로 뒤집기                                   \n",
        "                                   vertical_flip=True,\n",
        "                                   fill_mode='nearest'\n",
        "                                  ) \n",
        "# validation 및 test 이미지는 augmentation을 적용하지 않는다;\n",
        "# 모델 성능을 평가할 때에는 이미지 원본을 사용 (rescale만 진행)\n",
        "# train_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olD5BNgeSV5l",
        "outputId": "af8cbb46-61ed-41b7-eb0b-b56f4b42ef8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 78052 images belonging to 52 classes.\n",
            "Found 19552 images belonging to 52 classes.\n",
            "Found 47134 images belonging to 52 classes.\n"
          ]
        }
      ],
      "source": [
        "# flow_from_directory() 메서드를 이용해서 훈련과 테스트에 사용될 이미지 데이터를 만들기\n",
        "# 변환된 이미지 데이터 생성\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "                                                    # data_dir,\n",
        "                                                    # \"/content/drive/MyDrive/dataset/\",\n",
        "                                                    train_dir, \n",
        "                                                    batch_size=250, # 한번에 변환된 이미지 16개씩 만들어라 라는 것\n",
        "                                                    color_mode='grayscale', # 흑백 이미지 처리\n",
        "                                                    # class_mode='binary', \n",
        "                                                    class_mode='categorical',\n",
        "                                                    target_size=(150,150)) # target_size에 맞춰서 이미지의 크기가 조절된다\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "                                                              # data_dir,\n",
        "                                                              val_dir,\n",
        "                                                              # \"/content/drive/MyDrive/dataset/\",\n",
        "                                                              batch_size=128, \n",
        "                                                              color_mode='grayscale',\n",
        "                                                              # class_mode='binary', \n",
        "                                                              class_mode='categorical',\n",
        "                                                              target_size=(150,150))\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "                                                  batch_size=128,\n",
        "                                                  color_mode='grayscale',\n",
        "                                                  # class_mode='binary',\n",
        "                                                  class_mode='categorical',\n",
        "                                                  target_size=(150,150))\n",
        "# 참고로, generator 생성시 batch_size x steps_per_epoch (model fit에서) <= 훈련 샘플 수 보다 작거나 같아야 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_NSu0uCT2xw",
        "outputId": "8375d41f-5ce1-41c9-fedc-6ac5e727ef34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'A': 0,\n",
              " 'B': 1,\n",
              " 'C': 2,\n",
              " 'D': 3,\n",
              " 'E': 4,\n",
              " 'F': 5,\n",
              " 'G': 6,\n",
              " 'H': 7,\n",
              " 'I': 8,\n",
              " 'J': 9,\n",
              " 'K': 10,\n",
              " 'L': 11,\n",
              " 'M': 12,\n",
              " 'N': 13,\n",
              " 'O': 14,\n",
              " 'P': 15,\n",
              " 'Q': 16,\n",
              " 'R': 17,\n",
              " 'S': 18,\n",
              " 'T': 19,\n",
              " 'U': 20,\n",
              " 'V': 21,\n",
              " 'W': 22,\n",
              " 'X': 23,\n",
              " 'Y': 24,\n",
              " 'Z': 25,\n",
              " 'small_a': 26,\n",
              " 'small_b': 27,\n",
              " 'small_c': 28,\n",
              " 'small_d': 29,\n",
              " 'small_e': 30,\n",
              " 'small_f': 31,\n",
              " 'small_g': 32,\n",
              " 'small_h': 33,\n",
              " 'small_i': 34,\n",
              " 'small_j': 35,\n",
              " 'small_k': 36,\n",
              " 'small_l': 37,\n",
              " 'small_m': 38,\n",
              " 'small_n': 39,\n",
              " 'small_o': 40,\n",
              " 'small_p': 41,\n",
              " 'small_q': 42,\n",
              " 'small_r': 43,\n",
              " 'small_s': 44,\n",
              " 'small_t': 45,\n",
              " 'small_u': 46,\n",
              " 'small_v': 47,\n",
              " 'small_w': 48,\n",
              " 'small_x': 49,\n",
              " 'small_y': 50,\n",
              " 'small_z': 51}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# class 확인\n",
        "train_generator.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "b4ui5ErnU0bm"
      },
      "outputs": [],
      "source": [
        "# # 합성곱 신경망 모델 구성하기\n",
        "# import tensorflow as tf\n",
        "\n",
        "# model = tf.keras.models.Sequential([\n",
        "#     tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 1)),\n",
        "#     tf.keras.layers.MaxPooling2D(2,2),\n",
        "#     tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "#     tf.keras.layers.MaxPooling2D(2,2),\n",
        "#     tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "#     tf.keras.layers.MaxPooling2D(2,2),\n",
        "#     tf.keras.layers.Flatten(),\n",
        "#     tf.keras.layers.Dense(512, activation='relu'),\n",
        "#     # tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "#     tf.keras.layers.Dense(52, activation='softmax')\n",
        "# ])\n",
        "# model.summary() # 신경망의 구조 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUH2OG9UVsx_",
        "outputId": "a03604c6-cd56-4103-a688-a9e3ca4637ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_55 (Conv2D)          (None, 148, 148, 16)      160       \n",
            "                                                                 \n",
            " conv2d_56 (Conv2D)          (None, 146, 146, 16)      2320      \n",
            "                                                                 \n",
            " max_pooling2d_39 (MaxPoolin  (None, 73, 73, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_57 (Conv2D)          (None, 71, 71, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_40 (MaxPoolin  (None, 35, 35, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_58 (Conv2D)          (None, 33, 33, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_41 (MaxPoolin  (None, 16, 16, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_59 (Conv2D)          (None, 14, 14, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_60 (Conv2D)          (None, 12, 12, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_42 (MaxPoolin  (None, 6, 6, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 2304)              0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 512)               1180160   \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 52)                26676     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,278,628\n",
            "Trainable params: 1,278,628\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 합성곱 신경망 모델 구성하기\n",
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 1)),\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    # tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    # tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    tf.keras.layers.Dense(52, activation='softmax')\n",
        "])\n",
        "model.summary() # 신경망의 구조 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "yadtiWbEV4YA"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# compile() 메서드를 이용해서 손실 함수 (loss function)와 옵티마이저 (optimizer)를 지정\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics= ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qJWP-BrV9yK",
        "outputId": "25c03990-b3ae-4c8f-9d80-e5bc3c0af1e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 506s 48s/step - loss: 3.9443 - accuracy: 0.0216 - val_loss: 3.9175 - val_accuracy: 0.0234\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 461s 46s/step - loss: 3.9041 - accuracy: 0.0340 - val_loss: 3.7593 - val_accuracy: 0.0677\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 440s 44s/step - loss: 3.7323 - accuracy: 0.0628 - val_loss: 3.3214 - val_accuracy: 0.1667\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 423s 42s/step - loss: 3.4878 - accuracy: 0.1156 - val_loss: 2.8757 - val_accuracy: 0.1992\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 399s 40s/step - loss: 3.1743 - accuracy: 0.1424 - val_loss: 2.6182 - val_accuracy: 0.2279\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 393s 39s/step - loss: 3.0055 - accuracy: 0.1780 - val_loss: 2.4127 - val_accuracy: 0.2917\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 380s 38s/step - loss: 2.8545 - accuracy: 0.1908 - val_loss: 2.2593 - val_accuracy: 0.3385\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 364s 36s/step - loss: 2.7799 - accuracy: 0.2160 - val_loss: 2.1653 - val_accuracy: 0.3581\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 360s 36s/step - loss: 2.6297 - accuracy: 0.2376 - val_loss: 2.0328 - val_accuracy: 0.3750\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 347s 35s/step - loss: 2.5884 - accuracy: 0.2544 - val_loss: 2.0427 - val_accuracy: 0.3620\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 326s 33s/step - loss: 2.4699 - accuracy: 0.2656 - val_loss: 1.9189 - val_accuracy: 0.4271\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 325s 32s/step - loss: 2.3995 - accuracy: 0.2944 - val_loss: 1.9070 - val_accuracy: 0.3971\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 313s 31s/step - loss: 2.3513 - accuracy: 0.2848 - val_loss: 1.8202 - val_accuracy: 0.4349\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 295s 29s/step - loss: 2.3162 - accuracy: 0.3044 - val_loss: 1.7321 - val_accuracy: 0.4609\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 288s 29s/step - loss: 2.2188 - accuracy: 0.3316 - val_loss: 1.7338 - val_accuracy: 0.4570\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 282s 28s/step - loss: 2.2516 - accuracy: 0.3224 - val_loss: 1.7738 - val_accuracy: 0.4297\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 265s 26s/step - loss: 2.2089 - accuracy: 0.3320 - val_loss: 1.5806 - val_accuracy: 0.4987\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 258s 26s/step - loss: 2.2146 - accuracy: 0.3224 - val_loss: 1.6745 - val_accuracy: 0.4674\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 256s 25s/step - loss: 2.0906 - accuracy: 0.3400 - val_loss: 1.5175 - val_accuracy: 0.5078\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 250s 25s/step - loss: 2.0527 - accuracy: 0.3708 - val_loss: 1.5508 - val_accuracy: 0.4987\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 237s 23s/step - loss: 2.0287 - accuracy: 0.3724 - val_loss: 1.5842 - val_accuracy: 0.4648\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 227s 22s/step - loss: 2.0279 - accuracy: 0.3704 - val_loss: 1.5061 - val_accuracy: 0.5221\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 229s 22s/step - loss: 1.9972 - accuracy: 0.3680 - val_loss: 1.4369 - val_accuracy: 0.5430\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 219s 21s/step - loss: 1.9639 - accuracy: 0.3908 - val_loss: 1.5504 - val_accuracy: 0.5104\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 219s 22s/step - loss: 1.9457 - accuracy: 0.3916 - val_loss: 1.4983 - val_accuracy: 0.4987\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 209s 20s/step - loss: 1.9499 - accuracy: 0.3960 - val_loss: 1.4698 - val_accuracy: 0.5026\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 194s 19s/step - loss: 1.8444 - accuracy: 0.4170 - val_loss: 1.3444 - val_accuracy: 0.5221\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 198s 19s/step - loss: 1.8889 - accuracy: 0.4096 - val_loss: 1.3891 - val_accuracy: 0.5195\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 193s 19s/step - loss: 1.8729 - accuracy: 0.4072 - val_loss: 1.5112 - val_accuracy: 0.4870\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 180s 18s/step - loss: 1.8207 - accuracy: 0.4156 - val_loss: 1.4241 - val_accuracy: 0.5182\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 175s 17s/step - loss: 1.8111 - accuracy: 0.4460 - val_loss: 1.3059 - val_accuracy: 0.5794\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 173s 17s/step - loss: 1.7810 - accuracy: 0.4248 - val_loss: 1.2872 - val_accuracy: 0.5638\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 169s 17s/step - loss: 1.7886 - accuracy: 0.4348 - val_loss: 1.3909 - val_accuracy: 0.5378\n"
          ]
        }
      ],
      "source": [
        "# 모델 훈련\n",
        "history = model.fit_generator(train_generator, # train_generator안에 X값, y값 다 있으니 generator만 주면 된다\n",
        "                              validation_data=validation_generator, # validatino_generator안에도 검증용 X,y데이터들이 다 있으니 generator로 주면 됨\n",
        "                              steps_per_epoch=10, # 한 번의 에포크(epoch)에서 훈련에 사용할 배치(batch)의 개수 지정; generator를 4번 부르겠다\n",
        "                              epochs=100, # 데이터셋을 한 번 훈련하는 과정; epoch은 100 이상은 줘야한다\n",
        "                              # validation_steps=39, # 한 번의 에포크가 끝날 때, 검증에 사용되는 배치(batch)의 개수를 지정; validation_generator를 4번 불러서 나온 이미지들로 작업을 해라\n",
        "                              validation_steps=6,\n",
        "                              verbose=1)#0 출력 없음. 1 진행바 2 한줄씩\n",
        "# 참고: validation_steps는 보통 내가 원하는 이미지 수에 flow할 때 지정한 batchsize로 나눈 값을 validation_steps로 지정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CXqugpj_lgz"
      },
      "outputs": [],
      "source": [
        "# 모델 성능 평가\n",
        "model.evaluate(train_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnfmhRbV_mK9"
      },
      "outputs": [],
      "source": [
        "model.evaluate(validation_generator)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled7.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyORFGNFTzUFTsSxcg8I59/a"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}